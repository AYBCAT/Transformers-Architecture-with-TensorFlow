Transformer Network

This repository provides an educational implementation of the Transformer architecture using TensorFlow. It includes step-by-step Jupyter notebooks, visualizations, and explanations to help understand how Transformers work.

ðŸ“˜ In this notebook, we cover:

Creating positional encodings to capture sequential relationships in data

Calculating scaled dot-product self-attention with word embeddings

Implementing masked multi-head attention

Building and training a Transformer model from scratch
